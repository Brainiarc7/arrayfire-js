{"version":3,"names":[],"mappings":"","sources":["machine-learning/ann.js"],"sourcesContent":["\"use strict\";\n\nlet _ = require(\"lodash\");\nlet Bluebird = require(\"bluebird\");\nlet async = Bluebird.coroutine;\nlet debug = require(\"debug\")(\"af:ann\");\nlet now = require(\"performance-now\");\n\nfunction ANN(af, layers, range) {\n    range = range || 0.05;\n    this.af = af;\n    this.numLayers = layers.length;\n    this.signal = [];\n    this.weights = [];\n    for (let i = 0; i < this.numLayers; i++) {\n        this.signal.push(new af.AFArray());\n        if (i < this.numLayers - 1) {\n            let w = af.randu(layers[i] + 1, layers[i + 1], af.dType.f32).mul(range).sub(range / 2);\n            this.weights.push(w);\n        }\n    }\n}\n\nlet proto = ANN.prototype;\n\nproto.deriv = function (out) {\n    return out.rhsSub(1).mul(out);\n};\n\nproto.addBias = function (input) {\n    return this.af.join(1, this.af.constant(1, input.dims(0), this.af.dType.f32), input);\n};\n\nproto._calculateError = async(function*(out, pred) {\n    let dif = out.sub(pred);\n    return Math.sqrt(yield this.af.sumAsync(dif.mul(dif)));\n});\n\nproto.forwardPropagate = function (input) {\n    this.signal[0].set(input);\n    for (let i = 0; i < this.numLayers - 1; i++) {\n        let inVec = this.addBias(this.signal[i]);\n        let outVec = this.af.matMul(inVec, this.weights[i]);\n        this.signal[i + 1].set(this.af.sigmoid(outVec));\n    }\n};\n\nproto.backPropagate = function (target, alpha) {\n    let af = this.af;\n    let Seq = this.af.Seq;\n\n    // Get error for output layer\n    let outVec = this.signal[this.numLayers - 1];\n    let err = outVec.sub(target);\n    let m = target.dims(0);\n\n    for (let i = this.numLayers - 2; i >= 0; i--) {\n        let inVec = this.addBias(this.signal[i]);\n        let delta = af.transpose(this.deriv(outVec).mul(err));\n\n        // Adjust weights\n        let grad = af.matMul(delta, inVec).mul(alpha).neg().div(m);\n        this.weights[i].addAssign(af.transpose(grad));\n\n        // Input to current layer is output of previous\n        outVec = this.signal[i];\n        err.set(this.af.matMulTT(delta, this.weights[i]));\n\n        // Remove the error of bias and propagate backward\n        err.set(err.at(af.span, new Seq(1, outVec.dims(1))));\n    }\n};\n\nproto.predict = function (input) {\n    this.forwardPropagate(input);\n    return this.signal[this.numLayers - 1].copy();\n};\n\nproto.train = async(function*(input, target, options) {\n    let af = this.af;\n    let Seq = this.af.Seq;\n\n    let numSamples = input.dims(0);\n    let numBatches = numSamples / options.batchSize;\n\n    let err = 0;\n\n    for (let i = 0; i < options.maxEpochs; i++) {\n        const start = now();\n        for (let j = 0; j < numBatches - 1; j++) {\n            let startPos = j * options.batchSize;\n            let endPos = startPos + options.batchSize - 1;\n\n            let x = input.at(new Seq(startPos, endPos), af.span);\n            let y = target.at(new Seq(startPos, endPos), af.span);\n\n            this.forwardPropagate(x);\n            this.backPropagate(y, options.alpha);\n        }\n\n        // Validate with last batch\n        let startPos = (numBatches - 1) * options.batchSize;\n        let endPos = numSamples - 1;\n        let outVec = this.predict(input.at(new Seq(startPos, endPos), af.span));\n        err = yield this._calculateError(outVec, target.at(new Seq(startPos, endPos), af.span));\n        const end = now();\n\n        console.log(`Epoch: ${i + 1}, Error: ${err.toFixed(4)}, Duration: ${((end - start) / 1000).toFixed(4)} seconds`);\n\n        // Check if convergence criteria has been met\n        if (err < options.maxError) {\n            console.log(`Converged on Epoc: ${i + 1}`);\n            break;\n        }\n    }\n\n    return err;\n});\n\nmodule.exports = ANN;"],"file":"machine-learning/ann.js","sourceRoot":"/source/"}