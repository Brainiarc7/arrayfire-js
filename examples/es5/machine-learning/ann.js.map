{"version":3,"names":[],"mappings":"","sources":["machine-learning/ann.js"],"sourcesContent":["\"use strict\";\n\nlet _ = require(\"lodash\");\nlet Bluebird = require(\"bluebird\");\nlet async = Bluebird.coroutine;\nlet debug = require(\"debug\")(\"af:ann\");\nlet now = require(\"performance-now\");\n\nfunction ANN(af, layers, range) {\n    range = range || 0.05;\n    this.af = af;\n    this.numLayers = layers.length;\n    this.signal = [];\n    this.weights = [];\n    for (let i = 0; i < this.numLayers; i++) {\n        this.signal.push(new af.AFArray());\n        if (i < this.numLayers - 1) {\n            let w = af.randu(layers[i] + 1, layers[i + 1], af.dType.f32).mul(range).sub(range / 2);\n            this.weights.push(w);\n        }\n    }\n}\n\nlet proto = ANN.prototype;\n\nproto.deriv = function (out) {\n    return out.rhsSub(1).mul(out);\n};\n\nproto.addBias = function (input) {\n    return this.af.join(1, this.af.constant(1, input.dims(0), this.af.dType.f32), input);\n};\n\nproto._calculateError = async(function*(out, pred) {\n    let dif = out.sub(pred);\n    return Math.sqrt(yield this.af.sumAsync(dif.mul(dif)));\n});\n\nproto.forwardPropagate = function (input) {\n    this.signal[0].set(input);\n    for (let i = 0; i < this.numLayers - 1; i++) {\n        let self = this;\n        this.af.scope(function() {\n            let inVec = self.addBias(self.signal[i]);\n            let outVec = self.af.matMul(inVec, self.weights[i]);\n            self.signal[i + 1].set(self.af.sigmoid(outVec));\n        });\n    }\n};\n\nproto.backPropagate = function (target, alpha) {\n    let self = this;\n    let af = self.af;\n    let Seq = self.af.Seq;\n\n    // Get error for output layer\n    af.scope(function() {\n        let outVec = self.signal[self.numLayers - 1];\n        let err = outVec.sub(target);\n        let m = target.dims(0);\n\n        for (let i = self.numLayers - 2; i >= 0; i--) {\n            af.scope(function() {\n                let inVec = self.addBias(self.signal[i]);\n                let delta = af.transpose(self.deriv(outVec).mul(err));\n\n                // Adjust weights\n                let grad = af.matMul(delta, inVec).mul(alpha).neg().div(m);\n                self.weights[i].addAssign(af.transpose(grad));\n\n                // Input to current layer is output of previous\n                outVec = self.signal[i];\n                err.set(self.af.matMulTT(delta, self.weights[i]));\n\n                // Remove the error of bias and propagate backward\n                err.set(err.at(af.span, new Seq(1, outVec.dims(1))));\n            });\n        }\n    });\n};\n\nproto.predict = function (input) {\n    this.forwardPropagate(input);\n    return this.signal[this.numLayers - 1].copy();\n};\n\nproto.train = async(function*(input, target, options) {\n    let self = this;\n    let af = self.af;\n    let Seq = self.af.Seq;\n\n    let numSamples = input.dims(0);\n    let numBatches = numSamples / options.batchSize;\n\n    let err = 0;\n\n    for (let i = 0; i < options.maxEpochs; i++) {\n        const start = now();\n        for (let j = 0; j < numBatches - 1; j++) {\n            af.scope(function() {\n                let startPos = j * options.batchSize;\n                let endPos = startPos + options.batchSize - 1;\n\n                let x = input.at(new Seq(startPos, endPos), af.span);\n                let y = target.at(new Seq(startPos, endPos), af.span);\n\n                self.forwardPropagate(x);\n                self.backPropagate(y, options.alpha);\n            });\n        }\n\n        yield af.scope(async(function*() {\n            // Validate with last batch\n            let startPos = (numBatches - 1) * options.batchSize;\n            let endPos = numSamples - 1;\n            let outVec = self.predict(input.at(new Seq(startPos, endPos), af.span));\n            err = yield self._calculateError(outVec, target.at(new Seq(startPos, endPos), af.span));\n        }));\n\n        const end = now();\n        console.log(`Epoch: ${i + 1}, Error: ${err.toFixed(4)}, Duration: ${((end - start) / 1000).toFixed(4)} seconds`);\n\n        // Check if convergence criteria has been met\n        if (err < options.maxError) {\n            console.log(`Converged on Epoc: ${i + 1}`);\n            break;\n        }\n    }\n\n    return err;\n});\n\nmodule.exports = ANN;"],"file":"machine-learning/ann.js","sourceRoot":"/source/"}